---
cidr_networks: &cidr_networks
  container: 192.168.73.0/24
  tunnel: 172.16.0.0/12
  storage: 192.168.74.0/24

used_ips:
  - "192.168.73.40,192.168.73.44"
  - "192.168.74.40,192.168.74.44"
  - "172.16.0.41,172.16.0.42"

global_overrides:
  cidr_networks: *cidr_networks
  internal_lb_vip_address: 192.168.73.40
  #
  # The below domain name must resolve to an IP address
  # in the CIDR specified in haproxy_keepalived_external_vip_cidr.
  # If using different protocols (https/http) for the public/internal
  # endpoints the two addresses must be different.
  #
  external_lb_vip_address: openstack.imt
  tunnel_bridge: "br-vxlan"
  management_bridge: "br-mgmt"
  provider_networks:
    - network:
        container_bridge: "br-mgmt"
        container_type: "veth"
        container_interface: "eth1"
        ip_from_q: "container"
        type: "raw"
        group_binds:
          - all_containers
          - hosts
        is_container_address: true
        is_ssh_address: true
    - network:
        container_bridge: "br-vxlan"
        container_type: "veth"
        container_interface: "eth10"
        ip_from_q: "tunnel"
        type: "vxlan"
        range: "1:1000"
        net_name: "vxlan"
        group_binds:
          - neutron_linuxbridge_agent
#   - network:
#        container_bridge: "br-vlan"
#        container_type: "veth"
#        container_interface: "eth12"
#        host_bind_override: "eth12"
#        type: "flat"
#        net_name: "flat"
#        group_binds:
#          - neutron_linuxbridge_agent
    - network:
        container_bridge: "br-vlan"
        container_type: "veth"
        container_interface: "eth11"
        type: "vlan"
        range: "1:1"
        net_name: "vlan"
        group_binds:
          - neutron_linuxbridge_agent
    - network:
        container_bridge: "br-storage"
        container_type: "veth"
        container_interface: "eth2"
        ip_from_q: "storage"
        type: "raw"
        group_binds:
          - glance_api
          - cinder_api
          - cinder_volume
          - nova_compute
          - ceph-osd

###
### Infrastructure
###

_infrastructure_hosts: &infrastructure_hosts
  compute2:
    ip: 192.168.73.41
  compute3:
    ip: 192.168.73.42
  compute4:
    ip: 192.168.73.43

# nova hypervisors
compute_hosts: &compute_hosts
  compute2:
    ip: 192.168.73.41
  compute3:
    ip: 192.168.73.42
  compute4:
    ip: 192.168.73.43

ceph-osd_hosts:
  compute2:
    ip: 192.168.73.41
  compute3:
    ip: 192.168.73.42
  compute4:
    ip: 192.168.73.43

# galera, memcache, rabbitmq, utility
shared-infra_hosts: *infrastructure_hosts

# ceph-mon containers
ceph-mon_hosts: *infrastructure_hosts

# repository (apt cache, python packages, etc)
repo-infra_hosts: *infrastructure_hosts

# load balancer
# Ideally the load balancer should not use the Infrastructure hosts.
# Dedicated hardware is best for improved performance and security.
haproxy_hosts: *infrastructure_hosts

# rsyslog server
log_hosts:
  infra1:
    ip: 192.168.73.41

###
### OpenStack
###

# keystone
identity_hosts: *infrastructure_hosts

# cinder api services
storage-infra_hosts: *infrastructure_hosts

# cinder volume hosts (Ceph RBD-backed)
storage_hosts: *infrastructure_hosts

# glance
image_hosts: *infrastructure_hosts

# nova api, conductor, etc services
compute-infra_hosts: *infrastructure_hosts

# heat
orchestration_hosts: *infrastructure_hosts

# horizon
dashboard_hosts: *infrastructure_hosts

# neutron server, agents (L3, etc)
network_hosts: *infrastructure_hosts

# ceilometer (telemetry data collection)
metering-infra_hosts: *infrastructure_hosts

# aodh (telemetry alarm service)
metering-alarm_hosts: *infrastructure_hosts

# gnocchi (telemetry metrics storage)
metrics_hosts: *infrastructure_hosts

# ceilometer compute agent (telemetry data collection)
metering-compute_hosts: *compute_hosts
